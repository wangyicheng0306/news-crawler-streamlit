import streamlit as st
import requests
from bs4 import BeautifulSoup
import urllib.parse
import time
import schedule

# -------- çˆ¬è™«é€»è¾‘ -------- #
def fetch_baidu_news(query, max_results=5):
    query_encoded = urllib.parse.quote(query)
    url = f"https://www.baidu.com/s?tn=news&word={query_encoded}"
    headers = {"User-Agent": "Mozilla/5.0"}

    response = requests.get(url, headers=headers)
    response.encoding = 'utf-8'
    soup = BeautifulSoup(response.text, 'html.parser')

    results = []
    for item in soup.select('div.result')[:max_results]:
        a_tag = item.find('a')
        if a_tag:
            title = a_tag.get_text(strip=True)
            link = a_tag['href']
            results.append((title, link))
    return results

def fetch_sina_news(query, max_results=5):
    query_encoded = urllib.parse.quote(query)
    url = f"https://search.sina.com.cn/?q={query_encoded}&c=news"
    headers = {"User-Agent": "Mozilla/5.0"}

    response = requests.get(url, headers=headers)
    response.encoding = 'utf-8'
    soup = BeautifulSoup(response.text, 'html.parser')

    results = []
    for item in soup.select('div.box-result.clearfix')[:max_results]:
        h2_tag = item.find('h2')
        if h2_tag and h2_tag.a:
            title = h2_tag.a.get_text(strip=True)
            link = h2_tag.a['href']
            results.append((title, link))
    return results

# -------- Streamlit é¡µé¢ -------- #
st.title("ğŸ“° ä¸­æ–‡æ–°é—»çˆ¬è™«å·¥å…·ï¼ˆç™¾åº¦ + æ–°æµªï¼‰")
query = st.text_input("è¯·è¾“å…¥å…³é”®è¯", "2025å¹´4æœˆ ç¾å›½ å…³ç¨")

if st.button("ğŸ” å¼€å§‹æŠ“å–"):
    st.write("æ­£åœ¨æŠ“å–æ–°é—»ï¼Œè¯·ç¨å€™...")

    baidu_news = fetch_baidu_news(query)
    sina_news = fetch_sina_news(query)

    st.subheader("ğŸ“Œ ç™¾åº¦æ–°é—»")
    if baidu_news:
        for idx, (title, link) in enumerate(baidu_news, 1):
            st.markdown(f"{idx}. [{title}]({link})")
    else:
        st.write("æœªæŠ“åˆ°ç™¾åº¦æ–°é—»å†…å®¹")

    st.subheader("ğŸ“Œ æ–°æµªæ–°é—»")
    if sina_news:
        for idx, (title, link) in enumerate(sina_news, 1):
            st.markdown(f"{idx}. [{title}]({link})")
    else:
        st.write("æœªæŠ“åˆ°æ–°æµªæ–°é—»å†…å®¹")

# -------- å®šæ—¶ä»»åŠ¡é€»è¾‘ï¼ˆé€‰å¡«ï¼‰ -------- #
def scheduled_task():
    print("â° å®šæ—¶æŠ“å–ä¸€æ¬¡æ–°é—»...")
    fetch_baidu_news(query)
    fetch_sina_news(query)

# æ¯éš”30åˆ†é’ŸæŠ“ä¸€æ¬¡ï¼ˆå¦‚éœ€åå°è¿è¡Œè¯·å–æ¶ˆæ³¨é‡Šï¼‰
# schedule.every(30).minutes.do(scheduled_task)
# while True:
#     schedule.run_pending()
#     time.sleep(1)